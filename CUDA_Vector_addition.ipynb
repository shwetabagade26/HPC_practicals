{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgss_p-8m_rU",
        "outputId": "6cd631d3-1622-4ac0-c2f7-9ce0da538014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-x_i9jqnz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-x_i9jqnz\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/afnan47/cuda.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "__global__\n",
        "void add(int* A, int* B, int* C, int size) {\n",
        "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "if (tid < size) {\n",
        " C[tid] = A[tid] + B[tid];\n",
        "}\n",
        "}\n",
        "void initialize(int* vector, int size) {\n",
        "for (int i = 0; i < size; i++) {\n",
        " vector[i] = rand() % 10;\n",
        "}\n",
        "}\n",
        "void print(int* vector, int size) {\n",
        "for (int i = 0; i < size; i++) {\n",
        " cout << vector[i] << \" \";\n",
        "}\n",
        " cout << endl;\n",
        "}\n",
        "int main() {\n",
        "int N = 4;\n",
        "int* A, * B, * C;\n",
        "int vectorSize = N;\n",
        " size_t vectorBytes = vectorSize * sizeof(int);\n",
        " A = new int[vectorSize];\n",
        " B = new int[vectorSize];\n",
        " C = new int[vectorSize];\n",
        " initialize(A, vectorSize);\n",
        " initialize(B, vectorSize);\n",
        " cout << \"Vector A: \";\n",
        "print(A, N);\n",
        " cout << \"Vector B: \";\n",
        "print(B, N);\n",
        "int* X, * Y, * Z;\n",
        " cudaMalloc(&X, vectorBytes);\n",
        " cudaMalloc(&Y, vectorBytes);\n",
        " cudaMalloc(&Z, vectorBytes);\n",
        " cudaMemcpy(X, A, vectorBytes, cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(Y, B, vectorBytes, cudaMemcpyHostToDevice);\n",
        "int threadsPerBlock = 256;\n",
        "int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock; add<<<blocksPerGrid, threadsPerBlock>>>(X, Y, Z, N);\n",
        " cudaMemcpy(C, Z, vectorBytes, cudaMemcpyDeviceToHost);\n",
        " cout << \"Addition: \";\n",
        "print(C, N);\n",
        " delete[] A;\n",
        " delete[] B;\n",
        " delete[] C;\n",
        " cudaFree(X);\n",
        " cudaFree(Y);\n",
        " cudaFree(Z);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuDEYTgCrNMs",
        "outputId": "6ace791e-b458-4b54-c1f2-a032c4343b2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector A: 3 6 7 5 \n",
            "Vector B: 3 5 6 2 \n",
            "Addition: 0 0 0 0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sJMnfASjrXt2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}